---
title: "Analysis of eye-tracking data"
author: "Badaya, Baltais & Lu"
format: 
   clean-revealjs:
    logo: /_images/logo_mils.png
    footer: "Data analysis"
    include-in-header: 
      text: |
        <style>
        .center-xy {
          margin: 0;
          position: absolute;
          top: 40%;
          -ms-transform: translateY(-50%), translateX(-50%);
          transform: translateY(-50%), translateX(-50%);
        }
        </style>
editor: visual
---

# Welcome back!

## Welcome

::: {style="text-align: center"}
Any questions from yesterday? How was the lab experience?
:::

## Wooclap

![](_images/_session1/wooclap_D1.JPG)

## Plan for today

-   (Minimal) Data wrangling
- Data visualization
  - VWP
  - Reading
- Data analysis
  - VWP
  - Reading

## Before we start

Datasets for VWP & reading

## Data wrangling

Prior to analysis:

-   Import data
-   (Re)code levels of interest
-   Filter data (e.g., practice/filler trials, trials with no click/wrong answer)
-   Transform variables
-   Explore data

## Data wrangling

Import data

``` r
library(tidyverse)
library(here)

etdat <- read_delim('et_experimentdata.csv', delim = ";")
```

```{r}

#| echo: false
#| results: hide

library(tidyverse)
library(here)
library(lme4)

etdat <- read_csv('./_images/_session5/et_experimentdata.csv')

```

## Data wrangling {.smaller}

Recap of variables of interest (besides your experimental variables and session variables, for the analysis taught in this course)

::: columns
::: {.column width="60%"}
Visual World Paradigm

-   BIN_INDEX
-   BIN_SAMPLE_COUNT, the number of samples per bin (cf. session 4)
-   IA_X_ID, where X is the number of each interest area in your experiment.
-   AVERAGE_IA_X_SAMPLE_COUNT, where X is the number of the interest area (NB LEFT/RIGHT), counts.
-   AVERAGE_IA_X_SAMPLE_COUNT\_%, where X is the number of the interest area (NB LEFT/RIGHT), proportions.
-   AVERAGE_EXCLUDED_SAMPLE_COUNT, number of samples excluded from counts (NB LEFT/RIGHT; cf. session 5).
-   AVERAGE_BLINK_SAMPLE_COUNT (NB LEFT/RIGHT)
:::

::: {.column width="40%"}
Reading

-   IA_ID
-   IA_SKIP
-   IA_FIRST_FIXATION_DURATION
-   IA_FIRST_RUN_DWELL_TIME
-   IA_REGRESSION_IN
-   IA_REGRESSION_OUT
-   IA_REGRESSION_PATH_DURATION
-   IA_DWELL_TIME
-   Inter alia
:::
:::

# Data visualization

## Data visualization in eye-tracking

Different kinds of data are better explored in different visualizations.

-   What visualization conveys (in an informative way) your research question.
-   What variables you are interested in.
-   What stimuli you used.
    -   Principles for effective data visualization (Midway, 2020)

## Scan path

Pattern of fixations and saccades during a trial.

![](_images/_session5/scanpath.png){fig-align="center"}

## Bee swarm

![](_images/_session5/beeswarm.png){fig-align="center"}

## Heat map

![](_images/_session5/heatmap.png){fig-align="center"}

## Visual World Paradigm

-   Display of fixations over time.
    -   Can also do an animation.
    -   Fixations tend to be comparisons (fixations on the target versus the distractor).
-   Histograms might be possible.
-   Rarer to find tables.
    -   Except for model output, of course

## Visual World Paradigm

![Badaya et al., in prep.](_images/_session5/liedetection.jpg){fig-align="center"}

## Visual World Paradigm

![Amos et al., 2022](_images/_session5/amos2022.png){fig-align="center"}

## Visual World Paradigm

![Corley, 2010](_images/_session5/corley2010.png){fig-align="center"}

## Reading

::: columns
::: {.column width="50%"}
Plot differences in means per condition, e.g., with bar charts.

Many measures → many plots, so only report the most important (if at all).
:::

::: {.column width="50%"}
![Clifton et al., 2007](_images/_session5/reading6.png){fig-align="center"}
:::
:::

## Reading

Most common in papers: tables.

-   Means and SDs (descriptive statistics).
-   Model coefficients (inferential statistics).
-   For each dependent measure, area of interest, condition, group...

Often entire pages occupied by tables...

## Reading

![Staub et al., 2007](_images/_session5/reading5.png){fig-align="center"}

## Reading

Separate table per AI.

![Frisson et al., 2017](_images/_session5/reading4.png){fig-align="center"}

## Reading

Model output.

![Frisson et al., 2017](_images/_session5/reading3.png){fig-align="center"}

## Reading

::: columns
::: {.column width="50%"}
More interesting plots possible if e.g., repeated exposure (development over time) or continuous predictors.

![Cop et al., 2017](_images/_session5/reading2.png){fig-align="center"}
:::

::: {.column width="50%"}
![Drieghe & Chan Seem, 2022](_images/_session5/reading1.png){fig-align="center"}
:::
:::

## Data visualization

How to get these figures?

::: columns
::: {.column width="50%"}
Visual World Paradigm

-   Tricky with jamovi
-   R & ggplot
    -   OSF, github
    -   x-axis: time, y-axis: fixations, line(s): conditions of interest
-   Excel?
:::

::: {.column width="50%"}
Reading

-   Descriptive statistics with jamovi
-   Bar plots with jamovi/R/excel
:::
:::

## Descriptives {.smaller}

::: columns
::: {.column width="50%"}
VWP

-   NB: Visualizations, DV.
-   Proportion of fixations in each IA in a time window.
:::

::: {.column width="50%"}
Reading

-   Skipping rate (in %)
    -   Subsequent duration measures **only** reported for items that were not skipped during first pass reading.
    -   Remove skipped items from analysis.
-   Report fixation duration and regression rate measures for each condition.
    -   Mean and SD.
    -   Aggregate means per participants \> Mean of means
    -   Duration in ms.
:::
:::

# Data analysis

## Data analysis

What variables are you going to analyse? How are you going to conceptualise them?

-   DV: Fixations: counts? proportions? advantage? Reading times? Percentages?
-   IV: Categorical: contrast coding? dummy coding? Continuous: Center variable?

Covariates?

::: aside
This, in fact, is done when you're doing data wrangling, but we're discussing it here for the sake of flow.
:::

## Data analysis

Stimuli variables as covariates in analysis

::: columns
::: {.column width="50%"}
-   Word length
-   Phrase length
-   Sentence length
-   Word frequency
-   Familiarity
:::

::: {.column width="50%"}
-   Participants' age
-   Participants' gender
-   Proficiency
-   Inter alia
:::
:::

This does not mean you have to add them.

## Data analysis: Reporting

Just as a note:

-   It is good practice to report the software you used for analysis, version and reference.
    -   Same goes for packages.

## Data analysis

1.  What model answers your question?
2.  Does your data satisfy the model requirements?

-   Pre-defined data analysis (pre-registration)

## Data analysis

1.  What model answers your question

-   ANOVAs & t-test were originally conceived for categorical variables.

-   (Generalised) linear models cannot account for clusters in our data (e.g., participants' differences, items' differences).

-   Most papers using eye-tracking in the language sciences will employ (generalised) linear mixed models to account for these factors.

-   Random effects for participant and item (at least).

-   Multiple comparisons problem (see reading).

## Data analysis

2.  Models have assumptions that eye-tracking data does not meet.

-   Where the eye is at time *t* depends on where it was at time *t-1* (i.e., eye movements are not independent from one another, **autocorrelation**).
-   Eye-tracking data might not be continuous.
    -   Proportions are bounded.
    -   Reaction times are not normally distributed.

## Data analysis

2.  Models have assumptions that eye-tracking data does not meet.

-   Where the eye is at time *t* depends on where it was at time *t-1* (i.e., eye movements are not independent from one another).
    -   Aggregate into time bins and transformations (Barr, 2008).
    -   Include an autocorrelation factor.

![Stone et al., 2020](_images/_session5/autocorrelation.PNG)

## Data analysis

2.  Models have assumptions that eye-tracking data does not meet.

-   Eye-tracking data might not be continuous.
    -   Transformation of our dependent variable.
    -   Work with generalised models to accommodate a different link function.

# Visual World Paradigm

## Visual World Paradigm {.smaller}

How do we conceptualise our fixations?

-   Binary: Is there a fixation on this area of interest?
    -   Size of time bins
    -   Donnelly & Verkuilen (2017)
-   **Work with proportions**
    -   Bounded \[0, 1\]
    -   Transformation of counts: Empirical logits (Barr, 2008): log(count of fixations + .5 / (Total - count of fixations + .5))
        -   Where N will be the number of samples per bin (when working with time binning analysis)
    -   Other authors have proposed different transformations.
    -   Some might still argue it's not ideal (alternative: beta distribution?)

## Visual World Paradigm

```{r echo=FALSE}

library(tidyverse)
library(patchwork)

etdat_plot <- read_csv('./_images/_session5/et_experimentdataplot.csv')

etdat_plot <- etdat_plot %>%
  select(., c(RECORDING_SESSION_LABEL, TRIAL_INDEX, BIN_INDEX, AVERAGE_IA_1_SAMPLE_COUNT, `AVERAGE_IA_1_SAMPLE_COUNT_%`, BIN_SAMPLE_COUNT, AVERAGE_IA_2_SAMPLE_COUNT, `AVERAGE_IA_2_SAMPLE_COUNT_%`, d_pos)) %>%
  rename(., subject = RECORDING_SESSION_LABEL) %>%
  mutate(
    ref_fix = ifelse(d_pos == "(-256", AVERAGE_IA_2_SAMPLE_COUNT, AVERAGE_IA_1_SAMPLE_COUNT),
    ref_prop = ifelse(d_pos == "(-256", `AVERAGE_IA_2_SAMPLE_COUNT_%`, `AVERAGE_IA_1_SAMPLE_COUNT_%`)
  )  %>%
  mutate(
    ref_elog = log(ref_fix + 0.5/(BIN_SAMPLE_COUNT - ref_fix + 0.5))
  )

# visualization

dist_prop <- etdat_plot %>%
  ggplot(., aes(x = ref_prop)) + geom_density() + labs(
    title = "Density plot of proportion of fixations on the target",
    x = "Proportion of fixations",
    y = "Density"
  ) + theme_bw()
  
dist_elog <- etdat_plot %>%
  ggplot(., aes(x = ref_elog)) + geom_density() + labs(
    title = "Density plot of empirical logit fixations on the target",
    x = "Empirical logit of fixations",
    y = "Density"
  ) + theme_bw()

dist_prop | dist_elog

```

## Visual World Paradigm

What if ID doesn't contain the right information? (i.e., what was shown in it)

-   if & else statements knowing what IA_1, \_2 and so on are on your screen
-   Knowing the position of each element

## Visual World Paradigm

Note that when computing empirical logits you may also subtract blinks and off-screen fixations.

-   No consensus
-   Also depends on what constituted a sample in your export!

## Visual World Paradigm

Note that you can also conceptualise your DV differently within these transformations:

-   Proportion of fixations on an item
-   Advantage of an item (e.g., proportion of fixations on target - proportion of fixations on distractor)

## Visual World Paradigm pipeline

Example: eyetrackingR package

::: columns
::: {.column width="30%"}
![](_images/_session5/eyetrackingR1.JPG){fig-align="left"}
:::

::: {.column width="70%"}
![](_images/_session5/eyetrackingR2.JPG){fig-align="right"}
:::
:::

## Visual World Paradigm

Interest: Time window.

-   Average amount of fixations in a time window.
    -   Are there more fixations when X is present than when it's not?
    -   Answers about an average.

**Time course analysis**:

-   Do fixations increase/decrease over time?
-   When does this increase happen?
-   Linear v "Non-linear" analysis

## Visual World Paradigm

In R

``` r

# TW: 0 - 800 ms target onset
# elog_target predicted by fluency
# random intercepts by-participant and by-item
# maximal model (Barr et al., 2012)

mdl_max <- etdat %>%
  mutate(
    time = BIN_INDEX * 20 # my bins are of 20 ms
  ) %>%
  filter(time < 820) %>%
  lmer(
  elog_target ~ time * fluency +
    (1 + time*fluency | RECORDING_SESSION_LABEL) + (1 + time*fluency| target),
  data = .
)
```

## Visual World Paradigm

Example of average empirical logits on a time window: Dijkgraaf et al., 2017

::: columns
::: {.column width="50%"}
-   4-images array
-   DV: Average empirical logits on target
-   Time window: Verb onset
:::

::: {.column width="50%"}
![](_images/_session5/1.png){fig-align="center"} ![](_images/_session5/2.png){fig-align="center"}
:::
:::

## Visual World Paradigm {.smaller}

Example of binary fixations, time course analysis (bin analysis): Ito et al., 2018

::: columns
::: {.column width="50%"}
-   4-images array.
-   DV: Fixations the object in this time bin.
    -   Condition was dummy-coded.
-   Time window: Every 50 ms bin from 1000 ms before target word onset to 1000 ms.
    -   NB: Multiple comparisons problem (because the same model is run in each bin).
:::

::: {.column width="50%"}
![](_images/_session5/3.png){fig-align="center"}
:::
:::

## Visual World Paradigm

Example of binary fixations, time course analysis (time continuous): Bosker et al., 2014

-   2-images array.
-   DV: Is there a fixation on the LF object in this time bin (1) or not (0)?
-   Time window: Different time windows (fluent/disfluent).

![](_images/_session5/4.png){fig-align="center"} ![](_images/_session5/5.png){fig-align="center"}

## Visual World Paradigm

If you are only interested in whether there is an effect or not over time, fit a (generalised) linear mixed model, you would be fine (yet cf. assumptions of models).

But sometimes our questions revolve around specific times, or rate of increase/decrease (see also Stone et al., 2021; Ito & Knoeferle, 2022).

## Visual World Paradigm

Sometimes our questions revolve around specific times, or rate of increase/decrease (see also Stone et al., 2020; Ito & Knoeferle, 2022).

-   Growth Curve Analysis
-   Divergent Point Analysis
-   Generalised Additive Mixed Models
-   Cluster Permutation Analysis

## Visual World Paradigm

![](_images/_session5/9.png){fig-align="center"}

## VWP: Example GAMMs

![](_images/_session5/example_gamms.png){fig-align="center"}

## VWP: Example DPA

![](_images/_session5/fig3A_exp1elog.png){fig-align="center"}

## VWP: Example DPA

![](_images/_session5/fig4_distribution_onsets.png){fig-align="center"}

## VWP: Estimating DPA via GAMMs

Veríssimo & Lago (2025, pre-print)

![](_images/_session5/verssimo_gamms.png){fig-align="center"}
## VWP: What to report

-   Time window of analysis (and if there was a correction for triggering a saccade)
-   Transformation of the data, if any
    -   And its interpretation e.g., positive values indicate X.
-   Model specification (i.e., fixed and random effects structures)
    -   For categorical variables: coding scheme (e.g., contrast coding, what level is each contrast)
    -   For more complex models (e.g., DPA), you need to provide more descriptions (e.g., what was bootstrapped).
-   What determines significance
-   Order of results write-up:
    -   Usually, first a visualization, describe the graph \> contrast with the stats.
    -   When providing results of the statistics: estimate, SE, t-value/p-value/CI.

# Reading

## Reading

**Analysis per interest area!**

-   Create data subsets

If IA skipped on first pass --\> assign *NA* to certain measures

-   Day data pre-processing

## Reading

In R

``` r

# NB this is dependent on how many IAs you have
# in this example, we have five

precritIA <- rd_dat %>% filter(IA_ID == 2)
critIA <- rd_dat %>% filter(IA_ID == 3)
postcritIA <- rd_dat %>% filter(IA_ID == 4)

# filter for skipping, introduce NAs

# FFD, GD, RPD, regressions-out: remove trials (assign NAs) where IA was skipped on first pass
for (i in critIA$IA_SKIP) {
  ifelse(critIA$IA_SKIP[critIA$IA_SKIP == i] == 1, critIA$IA_FIRST_FIXATION_DURATION[critIA$IA_SKIP == i] <- NA, critIA$IA_FIRST_FIXATION_DURATION[critIA$IA_SKIP == i])
  ifelse(critIA$IA_SKIP[critIA$IA_SKIP == i] == 1, critIA$IA_FIRST_RUN_DWELL_TIME[critIA$IA_SKIP == i] <- NA, critIA$IA_FIRST_RUN_DWELL_TIME[critIA$IA_SKIP == i])
  ifelse(critIA$IA_SKIP[critIA$IA_SKIP == i] == 1, critIA$IA_REGRESSION_PATH_DURATION[critIA$IA_SKIP == i] <- NA, critIA$IA_REGRESSION_PATH_DURATION[critIA$IA_SKIP == i])
  ifelse(critIA$IA_SKIP[critIA$IA_SKIP == i] == 1, critIA$IA_REGRESSION_OUT[critIA$IA_SKIP == i] <- NA, critIA$IA_REGRESSION_OUT[critIA$IA_SKIP == i])}
```

## Reading

Dependent variables

-   **Generalised**
    -   Probabilities of regression/skipping/re-reading.
    -   Logistic regression (binomial distribution).
-   **Linear**
    -   Reading times (fixation durations in ms), regression/fixation counts.
    -   Different approaches possible.

## Reading

Continuous DV: reaction (incl. reading) times tend to be positively skewed compared to a normal distribution.

![Lo & Andrews, 2015](_images/_session5/11.png){fig-align="center"}

## Reading

Continuous DV: reaction (incl. reading) times tend to be positively skewed compared to a normal distribution.

::: columns
::: {.column width="50%"}
-   Option 1: Linear Mixed Models anyway
    -   Log or inverse transformation to satisfy normality assumption
    -   Box-Cox procedure (Osborne, 2019)
:::

::: {.column width="50%"}
![](_images/_session5/12.png){fig-align="center"}
:::
:::

::: notes
box cox procedure tells you what transformation to do, ejemplo lambda 1 is no transformation because it looks like normal
:::

## Reading

Continuous DV: reaction (incl. reading) times tend to be positively skewed compared to a normal distribution.

-   Option 1: Linear Mixed Models
    -   Some researchers combine data transformation with cutting off the outliers: \> 2.5 SD from the average per participant and per condition.
    -   But - potential loss of precious informative data.

## Reading

Continuous DV

::: columns
::: {.column width="50%"}
-   Option 1: Linear Mixed Models anyway
    -   Log or inverse transformation to satisfy normality assumption
    -   Box-Cox procedure (Osborne, 2019)
:::

::: {.column width="50%"}
<br>

![Puebla & Felser, 2022](_images/_session5/14.png){fig-align="center"}
:::
:::

## Reading

Continuous DV

::: columns
::: {.column width="50%"}
-   Option 2: Generalized Linear Mixed Models

"Rather than transforming the dependent variable to eliminate this deviation from normality, GLMM allows the researcher to select a theoretical distribution that matches the properties of measured RT." (Lo & Andrews, 2015)

-   E.g., Gamma distribution (identity link)
:::

::: {.column width="50%"}
![Lo & Andrews, 2015](_images/_session5/11.png){fig-align="center"}
:::
:::

## Reading

Continuous DV

-   Option 2: Generalized Linear Mixed Models

![Hermena et al., 2021](_images/_session5/15.png){fig-align="center"}

## Reading

-   Several dependent measures, IAs, hypotheses...
    -   **Correct for multiple comparisons!**
    -   Loss of power v false positives
-   Not standard yet although should be
    -   See von der Malsburg & Angele (2017). False positives and other statistical errors in standard analyses of eye movements in reading.

Bonferroni (most conservative), also Holm-Bonferroni, FDR...

-   E.g., 6 measures for the critical IA
    -   $\alpha$ / 6 = 0.05 / 6 = `r round(0.05/6,4)`

::: notes
Areas and hypothesis

Family of test. every analysis you do for an IA, every analysis you do for a hypothesis it's basically correcting for runing multiple test to find one thing, the more you test the more lilkely you are to run into a pos res

strict -\> correct for hypothesis and IA, but might be overshooting, people commonly correct for either and more commonly for IA

FALSE DISCOVERY RATE comes from genetics so different method Holm doesn't penalise all p-values the same way, so it's less conservative

difference between knowing where the effect is and where not (try to be specific and only analyse those times where you know an effect should be found) always remember that measures are cummulative so you need to understand how your measures are linked and can be affected e.g., FFD and gaze duration, gaze and regression path duration; not that it's plain wrong but then you'd need to explore what's happened and what are the diff that may lead to this

rule of thumb: an effect should arise in at least 2 measures because they are allegedly related -\> critised, what if your effect is only in one place huh
:::

## Reading: What do report

NB: Some parts are shared with VWP

-   Critical regions being analysed
-   Reading measures per region (with definition)
-   Models used for binary/continuous measures
-   If applicable: data transformations for continuous measures
-   Correction for multiple comparisons
-   If not described in pre-processing: How regions skipped on first pass were dealt with

## Exercises

Organise in groups of 5.

- Each group decides a RQ (with some theory underlying it)*.
- Design an experiment
- Specify the eye-tracking components (e.g., calibration and validation, drift, sampling rate, AOIs, triggers)
- Measures of interest
- Analysis strategy

* Doesn't have to be real. You can make something up just for the fun of it.

# Wrap up

## Wrap up

-   Visualizations are somehow field-conventional.
-   Analysis requires you to understand your data.
    -   Experimental design & distribution (e.g., skewness of RTs)
-   When running experiments, it is important to understand if what we have observed is truly attributable to our manipulation or just chance.
-   Depending on what you ask yourself, you may be interested in modelling linear or non-linear trends.
-   Commonly, we account for clusters within eye-tracking data with (G)LMM for participants and items.

## Wrap up of the course

Throughout this course, we have aimed to explain what is eye-tracking, and how it looks like in language research. We have focused on two paradigms, with the goal of explaining what is their underlying logic so you can easily transfer it to your own questions within your field. We have also focused on giving you a hands-down approach to eye-tracking, so that you feel confident about your abilities after this course!

Thoughts? You will send be a link on Ufora to give feedback :)


## References {.smaller}

Amos, R. M., Seeber, K. G., & Pickering, M. J. (2022). Prediction during simultaneous interpreting: Evidence from the visual-world paradigm. *Cognition*, 220, 104987.

Barr, D. J. (2008). Analyzing 'visual world'eyetracking data using multilevel logistic regression. *Journal of memory and language, 59*(4), 457-474.

Bosker, H. R., Quené, H., Sanders, T., & De Jong, N. H. (2014). Native 'um's elicit prediction of low-frequency referents, but non-native 'um's do not. *Journal of memory and language, 75*, 104-116.

Clifton, C., Staub, A., & Rayner, K. (2007). Eye movements in reading words and sentences. In R. P. G. Van Gompel, M. H. Fischer, W. S. Murray, & R. L. Hill (Eds.) *Eye Movements: A window on mind and brain* (pp. 341--371). Oxford: Elsevier.

Cop, U., Dirix, N., Assche, E. V., Drieghe, D., & Duyck, W. (2017). Reading a book in one or two languages? An eye movement study of cognate facilitation in L1 and L2 reading. *Bilingualism: Language and Cognition, 20*(4), 747--769. https://doi.org/10.1017/S1366728916000213

Corley, M. (2010). Making predictions from speech with repairs: Evidence from eye movements. *Language and Cognitive Processes, 25*(5), 706-727.

::: notes
check references
:::

## References {.smaller}

Dijkgraaf, A., Hartsuiker, R. J., & Duyck, W. (2017). Predicting upcoming information in native-language and non-native-language auditory word recognition. *Bilingualism: Language and Cognition, 20*(5), 917-930.

Drieghe, D., & Chan Seem, R. (2022). Parafoveal processing of repeated words during reading. *Psychonomic Bulletin & Review, 29*(4), 1451--1460. https://doi.org/10.3758/s13423-021-02054-0

Frisson, S., Harvey, D. R., & Staub, A. (2017). No prediction error cost in reading: Evidence from eye movements. *Journal of Memory and Language, 95*, 200--214. https://doi.org/10.1016/j.jml.2017.04.007

Hermena, E. W., Bouamama, S., Liversedge, S. P., & Drieghe, D. (2021). Does diacritics‐based lexical disambiguation modulate word frequency, length, and predictability effects? An eye‐movements investigation of processing Arabic diacritics. *PLOS ONE, 16*(11), e0259987. https://doi.org/10.1371/journal.pone.0259987

Ito, A., Pickering, M. J., & Corley, M. (2018). Investigating the time-course of phonological prediction in native and non-native speakers of English: A visual world eye-tracking study. *Journal of Memory and Language, 98*, 1-11.

Ito, A., & Knoeferle, P. (2022). Analysing data from the psycholinguistic visual-world paradigm: Comparison of different analysis methods. *Behavior Research Methods*, 1-33.

## References {.smaller}

Lo, S., & Andrews, S. (2015). To transform or not to transform: Using generalized linear mixed models to analyse reaction time data. *Frontiers in Psychology, 6*. https://www.frontiersin.org/articles/10.3389/fpsyg.2015.01171

Osborne, J. (2010). Improving your data transformations: Applying the Box-Cox transformation. *Practical Assessment, Research, and Evaluation, 15*(1). https://doi.org/10.7275/qbpc-gk17

Puebla, C., & Felser, C. (2022). Discourse Prominence and Antecedent Mis-Retrieval during Native and Non-Native Pronoun Resolution. Discours. Revue de Linguistique, Psycholinguistique et Informatique. A Journal of Linguistics, *Psycholinguistics and Computational Linguistics, 29*, Article 29. https://doi.org/10.4000/discours.11720

Staub, A., Rayner, K., Pollatsek, A., Hyönä, J., & Majewski, H. (2007). The time course of plausibility effects on eye movements in reading: Evidence from noun-noun compounds. Journal of Experimental Psychology. *Learning, Memory, and Cognition, 33*(6), 1162--1169. https://doi.org/10.1037/0278-7393.33.6.1162

## References {.smaller}

Stone, K., Lago, S., & Schad, D. J. (2021). Divergence point analyses of visual world data: Applications to bilingual research. *Bilingualism: Language and Cognition, 24*(5), 833-841.

Veríssimo, J. & Lago, S. (2025). *A novel method for detecting onsets of experimental effects in visual world eye-tracking*. Manuscript submitted for publication. Retrieved May 12, 2025, from https://osf.io/preprints/psyarxiv/yk4xb

von der Malsburg, T., & Angele, B. (2017). False positives and other statistical errors in standard analyses of eye movements in reading. *Journal of Memory and Language, 94*, 119--133. https://doi.org/10.1016/j.jml.2016.10.003
